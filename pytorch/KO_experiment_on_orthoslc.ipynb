{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674bf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from multiprocessing import Process, Manager, Value, Array, managers\n",
    "from numpy import genfromtxt\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from multiprocessing import Pool\n",
    "import collections\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "# from more_itertools import unique_everseen\n",
    "from Bio.Seq import Seq\n",
    "# from Bio import pairwise2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Bio import SeqIO\n",
    "from multiprocessing import Process\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde4917",
   "metadata": {},
   "source": [
    "# cluster alignment and contribution entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa43d3",
   "metadata": {},
   "source": [
    "## kalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f6f856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Kalign (3.3.2)\r\n",
      "\r\n",
      "Copyright (C) 2006,2019,2020,2021 Timo Lassmann\r\n",
      "\r\n",
      "This program comes with ABSOLUTELY NO WARRANTY; for details type:\r\n",
      "`kalign -showw'.\r\n",
      "This is free software, and you are welcome to redistribute it\r\n",
      "under certain conditions; consult the COPYING file for details.\r\n",
      "\r\n",
      "Please cite:\r\n",
      "  Lassmann, Timo.\r\n",
      "  \"Kalign 3: multiple sequence alignment of large data sets.\"\r\n",
      "  Bioinformatics (2019) \r\n",
      "  https://doi.org/10.1093/bioinformatics/btz795\r\n",
      "\r\n",
      "\r\n",
      "Usage: kalign  -i <seq file> -o <out aln> \r\n",
      "\r\n",
      "Options:\r\n",
      "\r\n",
      "   --format           : Output format. [Fasta]\r\n",
      "   --reformat         : Reformat existing alignment. [NA]\r\n",
      "   --gpo              : Gap open penalty. [5.5]\r\n",
      "   --gpe              : Gap extension penalty. [2.0]\r\n",
      "   --tgpe             : Terminal gap extension penalty. [1.0]\r\n",
      "   --version (-V/-v)  : Prints version. [NA]\r\n",
      "\r\n",
      "Examples:\r\n",
      "\r\n",
      "Passing sequences via stdin:\r\n",
      "\r\n",
      "   cat input.fa | kalign -f fasta > out.afa\r\n",
      "\r\n",
      "Combining multiple input files:\r\n",
      "\r\n",
      "   kalign seqsA.fa seqsB.fa seqsC.fa -f fasta > combined.afa\r\n",
      "\r\n",
      "[2023-02-06 02:25:29] :     LOG : No input files\r\n"
     ]
    }
   ],
   "source": [
    "! /data/docker_qiime2_share_container_E/bioinformatics-tools/kalign/base_3.3.2/bin/kalign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b8a62",
   "metadata": {},
   "source": [
    "! parallel -j 16 /data/docker_qiime2_share_container_E/bioinformatics-tools/kalign/base_3.3.2/bin/kalign \\\n",
    "-i /data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/E_coli_orthoslc/write_fasta/strict_core/{} \\\n",
    "-o /data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/E_coli_orthoslc/kalign/{} \\\n",
    "::: `ls /data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/E_coli_orthoslc/write_fasta/strict_core/` \\\n",
    ">  /data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/E_coli_orthoslc/log_kalign.txt 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a443edb",
   "metadata": {},
   "source": [
    "## calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f06828",
   "metadata": {},
   "source": [
    "### Shannon entropy\n",
    "\n",
    "$$ H = - \\sum_{i=1}^{n} p_i \\log_2 p_i $$\n",
    "\n",
    "where $p_i$ is the probability of sequence $i$ in the gene cluster and $n$ is the total number of sequences in the gene cluster. The entropy quantifies the diversity of the sequences in the gene cluster. A high entropy value indicates high diversity, and a low entropy value indicates low diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f093bf",
   "metadata": {},
   "source": [
    "### my equition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251048b",
   "metadata": {},
   "source": [
    "$$C_{seqs} = \\binom{list_{seqs}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e7c51",
   "metadata": {},
   "source": [
    "$$S_{contribution} = \\sum_{pair \\in C_{seqs}} bi_zhi * get_distance(pairs[0], pairs[1]) * (a + b) * (1/1127)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae9007e",
   "metadata": {},
   "source": [
    "$S_{contribution}$ Contrubution score of a gene cluster which reflect how much it affect tree inference.<br>\n",
    "$list_{seqs}$ list of unique sequences in a gene cluster.<br>\n",
    "$C_{seqs}$ combination of unique sequences pari in a gene cluster to be caculated.<br>\n",
    "$C_{seqs}$ combination of unique sequences pari in a gene cluster to be caculated.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba93d629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combinations([1,2,3], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197a897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaligned_path = 'E_coli_orthoslc/kalign/'\n",
    "\n",
    "def get_distance(str1, str2):\n",
    "    d = 0\n",
    "    l = len(str1)\n",
    "    \n",
    "    for c in range(l):\n",
    "        if str1[c] != str2[c]:\n",
    "            d = d + 1\n",
    "    d = d\n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_contribution(in_fasta_path, rt_dict):\n",
    "    in_fasta = SeqIO.to_dict(SeqIO.parse(kaligned_path + in_fasta_path,\n",
    "                                         'fasta')\n",
    "                            )\n",
    "    \n",
    "    rep_d = {}\n",
    "    \n",
    "    for keys in in_fasta.keys():\n",
    "        \n",
    "        seq = str(in_fasta[keys].seq)\n",
    "        \n",
    "        if seq in rep_d.keys():\n",
    "            rep_d[seq].append(keys)\n",
    "        else:\n",
    "            rep_d[seq] = [keys]\n",
    "            \n",
    "    key_lst = list(rep_d.keys())\n",
    "    \n",
    "    list_seqs = combinations(key_lst, 2)\n",
    "    \n",
    "    S_contribution = 0\n",
    "    \n",
    "    for pair in list_seqs:\n",
    "#         a = len(pair[0])\n",
    "#         b = len(pair[1])\n",
    "#         if a < b:\n",
    "#             bi_zhi = a/b\n",
    "#         else:\n",
    "#             bi_zhi = b/a\n",
    "    \n",
    "        a = len(rep_d[pair[0]]) # number of identical seqs of this representation in that cluster\n",
    "        b = len(rep_d[pair[1]])\n",
    "        \n",
    "#         S_contribution = bi_zhi*get_distance(pair[0], pair[1])*(a + b)**1/len(in_fasta.keys()\n",
    "#                                                                                        )\n",
    "#                                                                                  )\n",
    "        S_contribution = S_contribution + get_distance(pair[0], pair[1])*(a + b)\n",
    "    \n",
    "    rt_dict[in_fasta_path.replace('.fasta', '')] = [S_contribution, len(rep_d.keys()), len(pair[0])]\n",
    "    \n",
    "def divide_chunks(l, n):\n",
    "\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5cb09",
   "metadata": {},
   "source": [
    "```Python\n",
    "kaligned_path = 'E_coli_orthoslc/kalign/'# !!!! need before alignment\n",
    "\n",
    "def get_distance(str1, str2):\n",
    "    d = 0\n",
    "    l = len(str1)\n",
    "    \n",
    "    for c in range(len(str1)):\n",
    "        if str1[c] != str2[c]:\n",
    "            d = d + 1\n",
    "    d = d\n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_contribution(in_fasta_path, rt_dict):\n",
    "    in_fasta = SeqIO.to_dict(SeqIO.parse(kaligned_path + in_fasta_path,\n",
    "                                         'fasta')\n",
    "                            )\n",
    "    \n",
    "    rep_d = {}\n",
    "    \n",
    "    for keys in in_fasta.keys():\n",
    "        \n",
    "        seq = str(in_fasta[keys].seq)\n",
    "        \n",
    "        if seq in rep_d.keys():\n",
    "            rep_d[seq].append(keys)\n",
    "        else:\n",
    "            rep_d[seq] = [keys]\n",
    "            \n",
    "    key_lst = list(rep_d.keys())\n",
    "    \n",
    "    list_seqs = combinations(key_lst, 2)\n",
    "    \n",
    "    S_contribution = 0\n",
    "    \n",
    "    for pair in list_seqs:\n",
    "#         a = len(pair[0])\n",
    "#         b = len(pair[1])\n",
    "#         if a < b:\n",
    "#             bi_zhi = a/b\n",
    "#         else:\n",
    "#             bi_zhi = b/a\n",
    "\n",
    "        a = len(rep_d[pair[0]]) # number of identical seqs of this representation in that cluster\n",
    "        b = len(rep_d[pair[1]])\n",
    "        \n",
    "#         S_contribution = S_contribution + bi_zhi*get_distance(pair[0], pair[1])*(a + b)*(1/1127)\n",
    "        S_contribution = S_contribution + get_distance(pair[0], pair[1])*(a + b)*(1/1127)\n",
    "    \n",
    "    rt_dict[in_fasta_path.replace('.fasta', '')] = S_contribution\n",
    "    \n",
    "def divide_chunks(l, n):\n",
    "\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "500a3efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  8 22:38:43 2023\n",
      "final time usage 129.2027509212494\n",
      "Wed Feb  8 22:40:52 2023\n"
     ]
    }
   ],
   "source": [
    "start_time_external = time.time()\n",
    "print(time.asctime())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    procc_num = 16\n",
    "    \n",
    "    mission_lst = list(divide_chunks(os.listdir(kaligned_path),\n",
    "                                     procc_num\n",
    "                                    )\n",
    "                      )\n",
    "    \n",
    "    manager = Manager()\n",
    "    return_dict = manager.dict()\n",
    "    \n",
    "    for submissions in mission_lst:\n",
    "    \n",
    "        jobs = []\n",
    "\n",
    "        for x in range(0, len(submissions)):\n",
    "            p = Process(target = get_contribution,\n",
    "                        args = (submissions[x], \n",
    "                                return_dict\n",
    "                               )\n",
    "                       )\n",
    "            p.start()\n",
    "            jobs.append(p)\n",
    "\n",
    "\n",
    "        for z in jobs:\n",
    "            z.join()\n",
    "        \n",
    "end_time_external = time.time()\n",
    "print(\"final time usage \" + str(end_time_external - start_time_external))\n",
    "print(time.asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfa7e7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11002-12335</th>\n",
       "      <td>75319401</td>\n",
       "      <td>328</td>\n",
       "      <td>4358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10761-11925</th>\n",
       "      <td>27280561</td>\n",
       "      <td>238</td>\n",
       "      <td>2853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10416-10370</th>\n",
       "      <td>20438341</td>\n",
       "      <td>222</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10725-12709</th>\n",
       "      <td>19374959</td>\n",
       "      <td>202</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938-12546</th>\n",
       "      <td>19092397</td>\n",
       "      <td>282</td>\n",
       "      <td>2769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11107-11787</th>\n",
       "      <td>4520</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11057-11102</th>\n",
       "      <td>3389</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11110-11410</th>\n",
       "      <td>3387</td>\n",
       "      <td>4</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11109-13487</th>\n",
       "      <td>3381</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11036-13780</th>\n",
       "      <td>2261</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0    1     2\n",
       "11002-12335  75319401  328  4358\n",
       "10761-11925  27280561  238  2853\n",
       "10416-10370  20438341  222  2818\n",
       "10725-12709  19374959  202  2044\n",
       "10938-12546  19092397  282  2769\n",
       "...               ...  ...   ...\n",
       "11107-11787      4520    5    95\n",
       "11057-11102      3389    4    87\n",
       "11110-11410      3387    4   228\n",
       "11109-13487      3381    2    85\n",
       "11036-13780      2261    3    77\n",
       "\n",
       "[725 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(return_dict, orient='index')\n",
    "df = df.sort_values(by = [0], ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb40730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('E_coli_orthoslc/cluster_contribution.csv',\n",
    "          header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df293886",
   "metadata": {},
   "source": [
    "# KO genome construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40718729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E_coli_orthoslc/cluster_contribution.csv', \n",
    "                 header = None)\n",
    "\n",
    "# with open('/data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/strains_id.json', 'r') as f_read:\n",
    "#     read = json.load(f_read)\n",
    "# print(len(read))\n",
    "\n",
    "with open('E_coli_orthoslc/Step1_pre_res.txt', 'r') as f_read:\n",
    "    rls = f_read.readlines()\n",
    "    \n",
    "    \n",
    "d = {}\n",
    "for x in rls:\n",
    "    l_ = x.rstrip('\\n').split('\\t')\n",
    "    d[l_[0]] = l_[1]\n",
    "    \n",
    "f_read.close()\n",
    "    \n",
    "# inv_map = {str(v): k for k, v in d.items()}\n",
    "inv_map = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d81a37b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11002-12335</td>\n",
       "      <td>75319401</td>\n",
       "      <td>328</td>\n",
       "      <td>4358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10761-11925</td>\n",
       "      <td>27280561</td>\n",
       "      <td>238</td>\n",
       "      <td>2853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10416-10370</td>\n",
       "      <td>20438341</td>\n",
       "      <td>222</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10725-12709</td>\n",
       "      <td>19374959</td>\n",
       "      <td>202</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10938-12546</td>\n",
       "      <td>19092397</td>\n",
       "      <td>282</td>\n",
       "      <td>2769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10586-10463</td>\n",
       "      <td>18388556</td>\n",
       "      <td>199</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10671-12852</td>\n",
       "      <td>18176041</td>\n",
       "      <td>221</td>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10503-14515</td>\n",
       "      <td>17526699</td>\n",
       "      <td>220</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10961-13268</td>\n",
       "      <td>16291195</td>\n",
       "      <td>158</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10076-11950</td>\n",
       "      <td>15440429</td>\n",
       "      <td>185</td>\n",
       "      <td>1623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10596-13386</td>\n",
       "      <td>14755535</td>\n",
       "      <td>198</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10992-11510</td>\n",
       "      <td>14469473</td>\n",
       "      <td>215</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11046-11448</td>\n",
       "      <td>14465653</td>\n",
       "      <td>208</td>\n",
       "      <td>1713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11115-13834</td>\n",
       "      <td>13965215</td>\n",
       "      <td>170</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10777-13591</td>\n",
       "      <td>13949677</td>\n",
       "      <td>247</td>\n",
       "      <td>2787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11018-13923</td>\n",
       "      <td>13469944</td>\n",
       "      <td>200</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10514-11808</td>\n",
       "      <td>13458781</td>\n",
       "      <td>218</td>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10579-11406</td>\n",
       "      <td>13286158</td>\n",
       "      <td>222</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11016-14260</td>\n",
       "      <td>12979333</td>\n",
       "      <td>167</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10468-12020</td>\n",
       "      <td>12911712</td>\n",
       "      <td>203</td>\n",
       "      <td>2683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1    2     3\n",
       "0   11002-12335  75319401  328  4358\n",
       "1   10761-11925  27280561  238  2853\n",
       "2   10416-10370  20438341  222  2818\n",
       "3   10725-12709  19374959  202  2044\n",
       "4   10938-12546  19092397  282  2769\n",
       "5   10586-10463  18388556  199  1501\n",
       "6   10671-12852  18176041  221  2390\n",
       "7   10503-14515  17526699  220  2704\n",
       "8   10961-13268  16291195  158  1140\n",
       "9   10076-11950  15440429  185  1623\n",
       "10  10596-13386  14755535  198  2044\n",
       "11  10992-11510  14469473  215  1555\n",
       "12  11046-11448  14465653  208  1713\n",
       "13  11115-13834  13965215  170  1656\n",
       "14  10777-13591  13949677  247  2787\n",
       "15  11018-13923  13469944  200  2089\n",
       "16  10514-11808  13458781  218  2666\n",
       "17  10579-11406  13286158  222  1984\n",
       "18  11016-14260  12979333  167  1647\n",
       "19  10468-12020  12911712  203  2683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0: 20, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2deb7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(df[0])\n",
    "\n",
    "# for x in a[715: ]:\n",
    "for x in a[0: 50]:\n",
    "    a.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede74534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4688f",
   "metadata": {},
   "source": [
    "to_skip = a[0: 1]\n",
    "to_skip.extend(a[700: ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ead1b7",
   "metadata": {},
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b178e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_skip = a\n",
    "len(to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf5baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaligned_path = '/data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/E_coli_orthoslc/kalign/'\n",
    "final_core_genome_path = \"/data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/E_coli_orthoslc/the_core_genome_1127.fasta\"\n",
    "\n",
    "to_write = []\n",
    "\n",
    "seq_coll = {}\n",
    "\n",
    "ini_seq = SeqIO.to_dict(SeqIO.parse(kaligned_path + \"10004-14472.fasta\", \n",
    "                                    \"fasta\")\n",
    "                       )\n",
    "for x in ini_seq:\n",
    "    seq_coll[inv_map[x[0: 5]]] = \"\"\n",
    "\n",
    "for x in os.listdir(kaligned_path):\n",
    "#     print(x)\n",
    "    x_fasta = SeqIO.to_dict(SeqIO.parse(kaligned_path + x, \n",
    "                                        \"fasta\")\n",
    "                           )\n",
    "    \n",
    "    if x.replace('.fasta', '') in to_skip:\n",
    "        for y in x_fasta:\n",
    "            seq_coll[inv_map[y[0: 5]\n",
    "                            ]\n",
    "                    ] = seq_coll[inv_map[y[0: 5]\n",
    "                                        ]\n",
    "                                ] + '-' * len(x_fasta[y].seq\n",
    "                                             )\n",
    "    else:\n",
    "        for y in x_fasta:\n",
    "            seq_coll[inv_map[y[0: 5]\n",
    "                            ]\n",
    "                    ] = seq_coll[inv_map[y[0: 5]\n",
    "                                        ]\n",
    "                                ] + str(x_fasta[y].seq)\n",
    "\n",
    "for z in seq_coll:\n",
    "    to_write.append(SeqRecord(id = z, \n",
    "                              name = z,\n",
    "                              description = \"\",\n",
    "                              dbxrefs=[],\n",
    "                              seq = Seq(seq_coll[z])\n",
    "                             )\n",
    "                   )\n",
    "with open(final_core_genome_path, \"w\") as output_handle:\n",
    "        SeqIO.write(to_write, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aed9fd",
   "metadata": {},
   "source": [
    "## for the phy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c68e03",
   "metadata": {},
   "source": [
    "```Python\n",
    "kaligned_path = '/data/docker_qiime2_share_G/Hejunwei/core_genome_study/genes_of_clusters/kaligned/'\n",
    "final_core_genome_path = \"/data/docker_qiime2_share_G/Hejunwei/core_genome_study/CNN/the_core_genome_1127_KO.phy\"# ！！！！\n",
    "\n",
    "to_write = []\n",
    "\n",
    "seq_coll = {}\n",
    "\n",
    "ini_seq = SeqIO.to_dict(SeqIO.parse(kaligned_path + \"10001-14085.fasta\", \n",
    "                                    \"fasta\")\n",
    "                       )\n",
    "for x in ini_seq:\n",
    "    seq_coll[inv_map[x[0: 5]]] = \"\"\n",
    "\n",
    "for x in os.listdir(kaligned_path):\n",
    "#     print(x)\n",
    "    x_fasta = SeqIO.to_dict(SeqIO.parse(kaligned_path + x, \n",
    "                                        \"fasta\")\n",
    "                           )\n",
    "    \n",
    "    if x.replace('.fasta', '') in to_skip:\n",
    "#         for y in x_fasta:\n",
    "#             seq_coll[inv_map[y[0: 5]\n",
    "#                             ]\n",
    "#                     ] = seq_coll[inv_map[y[0: 5]\n",
    "#                                         ]\n",
    "#                                 ] + '-' * len(x_fasta[y].seq\n",
    "#                                              )\n",
    "        continue\n",
    "    else:\n",
    "        for y in x_fasta:\n",
    "            seq_coll[inv_map[y[0: 5]\n",
    "                            ]\n",
    "                    ] = seq_coll[inv_map[y[0: 5]\n",
    "                                        ]\n",
    "                                ] + str(x_fasta[y].seq)\n",
    "\n",
    "for z in seq_coll:\n",
    "    to_write.append(SeqRecord(id = z, \n",
    "                              name = z,\n",
    "                              description = \"\",\n",
    "                              dbxrefs=[],\n",
    "                              seq = Seq(seq_coll[z])\n",
    "                             )\n",
    "                   )\n",
    "with open(final_core_genome_path, \"w\") as output_handle:\n",
    "        SeqIO.write(to_write, output_handle, \"phylip-relaxed\")\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4904c05",
   "metadata": {},
   "source": [
    "koed_fasta = SeqIO.to_dict(SeqIO.parse(final_core_genome_path, \n",
    "                                    \"phylip-relaxed\")\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f263621",
   "metadata": {},
   "source": [
    "len(koed_fasta['11368'].seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691717d7",
   "metadata": {},
   "source": [
    "# ```Shell\n",
    "#cd /data/docker_qiime2_share_G/Hejunwei/core_genome_study/CNN/RAxML_with_several_gene_left\n",
    "\n",
    "cd /data/docker_qiime2_share_G/Hejunwei/core_genome_study/CNN/RAxML_with_top50_left\n",
    "date ; raxmlHPC-PTHREADS-SSE3 \\\n",
    "-m GTRCAT -f a -p 1000 -# 1000 -x 1000 \\\n",
    "-s /data/docker_qiime2_share_G/Hejunwei/core_genome_study/CNN/the_core_genome_1127_KO.phy -n KOed_1127 -T 36 ; date\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e83c8",
   "metadata": {},
   "source": [
    "# pt np construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_d = {'A': [0],\n",
    "#           'T': [1],\n",
    "#           'C': [2],\n",
    "#           'G': [3],\n",
    "#           'Y': [1, 2], # T, C\n",
    "#           'R': [0, 3], # A, G\n",
    "#           'S': [2, 3], # C, G\n",
    "#           'W': [0, 1], # A, T\n",
    "#           'K': [1, 3], # G, Te\n",
    "#           'M': [0, 2], # A, C\n",
    "#           'B': [1, 2, 3], # T, C, G\n",
    "#           'D': [0, 1, 3], # A, T, G\n",
    "#           'H': [0, 1, 2], # A, T, C\n",
    "#           'V': [0, 2, 3], # A, C, G\n",
    "#           'N': [0, 1, 2, 3]\n",
    "# #           '-': None\n",
    "#          }\n",
    "\n",
    "conv_d = {'A': [1., 0., 0., 0.],\n",
    "          'T': [0., 1., 0., 0.],\n",
    "          'C': [0., 0., 1., 0.],\n",
    "          'G': [0., 0., 0., 1.],\n",
    "          'Y': [0., 0.5, 0.5, 0.], # T, C\n",
    "          'R': [0.5, 0., 0., 0.5], # A, G\n",
    "          'S': [0., 0., 0.5, 0.5], # C, G\n",
    "          'W': [0.5, 0.5, 0., 0.], # A, T\n",
    "          'K': [0., 0.5, 0., 0.5], # G, T\n",
    "          'M': [0.5, 0., 0.5, 0.], # A, C\n",
    "          'B': [0., 1/3, 1/3, 1/3], # T, C, G\n",
    "          'D': [1/3, 1/3, 0., 1/3], # A, T, G\n",
    "          'H': [1/3, 1/3, 1/3, 0.], # A, T, C\n",
    "          'V': [1/3, 0., 1/3, 1/3], # A, C, G\n",
    "          'N': [0.25, 0.25, 0.25, 0.25],\n",
    "          '-': [0., 0., 0., 0.]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a79e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_genome_fasta = SeqIO.to_dict(SeqIO.parse('/data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/E_coli_orthoslc/the_core_genome_1127.fasta',\n",
    "                                              'fasta'\n",
    "                                             )\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2642a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_path = '/data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/np/'\n",
    "\n",
    "def one_hot_encoding(sequence, conv_d_):\n",
    "    \n",
    "    seq_tensor = [conv_d_[base] for base in sequence]\n",
    "    seq_tensor = torch.tensor(seq_tensor).t()\n",
    "    \n",
    "    return seq_tensor\n",
    "\n",
    "def DNA_to_pt(core_genomes, in_lst, convert_dict):\n",
    "    \n",
    "    for f in in_lst:\n",
    "        s_seq = str(core_genomes[f].seq) \n",
    "        \n",
    "        b_seq = one_hot_encoding(s_seq, convert_dict)\n",
    "        \n",
    "        torch.save(b_seq, \n",
    "                   pt_path\n",
    "                   + f \n",
    "                   + '.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fec9c8",
   "metadata": {},
   "source": [
    "len(core_genome_fasta['536'].seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1871ac6",
   "metadata": {},
   "source": [
    "position = 0\n",
    "for x in core_genome_fasta['536'].seq:\n",
    "    if x != '-':\n",
    "        print(position)\n",
    "        break\n",
    "    else:\n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f09467",
   "metadata": {},
   "source": [
    "core_genome_fasta['536'].seq[0: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0329d6",
   "metadata": {},
   "source": [
    "test_tensor = torch.tensor(one_hot_encoding(str(core_genome_fasta['536'].seq[0: 10]), \n",
    "                                            conv_d)\n",
    "                          ).t()\n",
    "\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc1b05",
   "metadata": {},
   "source": [
    "test_tensor\n",
    "#test_tensor[:, :, 0: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d7570",
   "metadata": {},
   "source": [
    "torch.save(test_tensor, 'np/test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392db5f",
   "metadata": {},
   "source": [
    "loaded_sequence_tensor = torch.load('np/test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a50bf1",
   "metadata": {},
   "source": [
    "loaded_sequence_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339587a",
   "metadata": {},
   "source": [
    "np_path = '/data/docker_qiime2_share_container_D/to_github/pt/CoreDL/pt/np/'\n",
    "\n",
    "def DNA_to_np(core_genomes, in_lst, convert_dict):\n",
    "    check_lst = list(convert_dict.keys())\n",
    "    \n",
    "    for f in in_lst:\n",
    "        s_seq = str(core_genomes[f].seq) \n",
    "        \n",
    "        b_seq = np.zeros([4, len(s_seq)], \n",
    "                         dtype = 'int'\n",
    "                        )\n",
    "        \n",
    "        # vlauing\n",
    "        for x in range(len(s_seq)):\n",
    "            if s_seq[x] not in check_lst:\n",
    "                continue\n",
    "            else:\n",
    "                length = len(convert_dict[s_seq[x]])\n",
    "                \n",
    "                for y in convert_dict[s_seq[x]]:\n",
    "                    b_seq[convert_dict[s_seq[x]], x] = 1/length\n",
    "\n",
    "        with open(np_path\n",
    "                  + f \n",
    "                  + '.npy',\n",
    "                  'wb') as f:\n",
    "            np.save(f, b_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e658b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  8 23:16:56 2023\n",
      "final time usage 43.908437728881836\n",
      "Wed Feb  8 23:17:40 2023\n"
     ]
    }
   ],
   "source": [
    "start_time_external = time.time()\n",
    "print(time.asctime())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    procc_num = 8\n",
    "    \n",
    "    mission_lst = np.array_split(list(core_genome_fasta.keys()), \n",
    "                                 procc_num\n",
    "                                )\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    for x in range(0, procc_num):\n",
    "        p = Process(target = DNA_to_pt,\n",
    "                    args = (core_genome_fasta, \n",
    "                            mission_lst[x], \n",
    "                            conv_d\n",
    "                           )\n",
    "                   )\n",
    "        p.start()\n",
    "        jobs.append(p)\n",
    "        \n",
    "    \n",
    "    for z in jobs:\n",
    "        z.join()\n",
    "        \n",
    "end_time_external = time.time()\n",
    "print(\"final time usage \" + str(end_time_external - start_time_external))\n",
    "print(time.asctime())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
